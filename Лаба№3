1. Возможные гиперпараметры модели линейной регрессии:
-Возможные гиперпараметры модели линейной регрессии:
-Смещение (bias): Выполняет функцию корректировки или сдвига линии регрессии.
-Скорость обучения (learning rate): Определяет размер проходимого шага на каждой итерации в процессе поиска минимума функции потерь.
-Регуляризация:
-L1 Regularization (Lasso): Добавляет штраф, который пропорционален абсолютной величине коэффициентов.
-L2 Regularization (Ridge): Добавляет штраф, который пропорционален квадрату коэффициентов.
-Elastic Net: Комбинирует эффекты L1 и L2 регуляризации.
-Коэффициент регуляризации (alpha): Указывает на степень влияния регуляризационного штрафа.
-Термин рандомизации (random_state): Используется для гарантии воспроизводимости процесса обучения.
-Количество итераций (max_iter): Определяет максимальное количество итераций, которые модель может выполнить.

2. Может ли коэффициент детерминации (R²) быть отрицательным числом?
Коэффициент детерминации может иметь отрицательное значение, он является индикатором доли дисперсии зависимой переменной, объясняемой независимыми переменными. 
Если модель оказывается хуже, чем простое предсказание основываясь на среднем значении зависимой переменной, коэффициент детерминации будет меньше нуля.

3. Оценка MSE (Mean Squared Error) для данных:
Реальные значения y: {1, 2, 3, 4}
Предсказанные значения: {2, 1, 4, 6}

MSE = (1/4) * [(1-2)² + (2-1)² + (3-4)² + (4-6)²]
     = (1/4) * [1 + 1 + 1 + 4]
     = (1/4) * 7
     = 1.75
Для вычисления среднеквадратической ошибки (MSE, Mean Squared Error) в Python, можно использовать библиотеку numpy, которая облегчает работу с массивами и математические операции. 
MSE является популярной метрикой для оценки точности числовых предсказаний, и она рассчитывается как среднее квадратов разностей между истинными и предсказанными значениями.

Формула MSE:

[ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 ]

где:

( y_i ) — истинное значение,
( \hat{y}_i ) — предсказанное значение,
( n ) — количество элементов в данных.

import numpy as np

def mean_squared_error(y_true, y_pred):
    """Вычисление среднеквадратической ошибки (MSE)"""
    # Преобразуем списки в массивы numpy для удобства вычислений
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    # Вычисляем квадраты разностей
    squared_errors = (y_true - y_pred) ** 2
    # Среднее значение квадратов разностей
    mse = squared_errors.mean()
    return mse

# Истинные значения
y_true = [1, 2, 3, 4]
# Предсказанные значения
y_pred = [2, 1, 4, 6]

# Вычисление MSE
mse_result = mean_squared_error(y_true, y_pred)

print(f"MSE для заданных данных: {mse_result:.2f}")
Пояснение кода:
1. Функция mean_squared_error оперирует двумя наборами данных: y_true, представляющими реальные значения, и y_pred, содержащими предсказанные моделью значения.
   Эти наборы преобразуются в NumPy массивы для облегчения математических расчетов.
2. Затем вычисляются квадраты отклонений между соответствующими элементами этих двух массивов.
3. Средний квадрат отклонений (MSE) определяется путем применения метода .mean() к массиву полученных квадратов.
4. В завершение, результат выводится с округлением до двух десятичных знаков для более аккуратного и читаемого представления информации.

4. Рассчитайте обновленный вектор весов:
Вектор весов w: {10, 5, 6}
Градиент функции потерь: {20, -10, 40}
Скорость обучения: 0.1

Обновленный вектор весов w_new = w - learning_rate * gradient
                             = {10, 5, 6} - 0.1 * {20, -10, 40}
                             = {10, 5, 6} - {2, -1, 4}
                             = {8, 6, 2}

В рамках градиентного спуска, обновление вектора весов может быть выполнено с использованием Python для вычисление необходимых выражений.
Обновление осуществляется путем вычитания произведения скорости обучения и градиента, связанного с данными весов. Это общий подход, используемый в алгоритмах машинного обучения, особенно при обучении нейронных сетей.
Формула обновления весов:
[ w_{\text{new}} = w - \text{learning_rate} \times \text{gradient} ]

Где:
( w ) — текущий вектор весов,
( \text{gradient} ) — градиент функции потерь по весам,
( \text{learning_rate} ) — скорость обучения (шаг обучения).

import numpy as np

def update_weights(w, gradient, learning_rate):
    """Обновление вектора весов по правилу градиентного спуска."""
    # Преобразование списков в массивы NumPy для удобства вычислений
    w = np.array(w)
    gradient = np.array(gradient)
    # Вычисление обновленного вектора весов
    w_new = w - learning_rate * gradient
    return w_new

# Исходный вектор весов
w = [10, 5, 6]
# Градиент функции потерь
gradient = [20, -10, 40]
# Скорость обучения
learning_rate = 0.1

# Вычисление нового вектора весов
w_new = update_weights(w, gradient, learning_rate)

print("Обновленный вектор весов:", w_new)

Пояснение кода:

1. Функция update_weights принимает три аргумента: текущий вектор весов w, градиент gradient и скорость обучения learning_rate.
2. Внутри функции, оба аргументы w и gradient преобразуются в массивы NumPy, что упрощает векторизованные операции над ними.
3. Новый вектор весов рассчитывается путем вычитания произведения скорости обучения и градиента из текущего вектора весов.
4. Результирующий массив NumPy возвращается в качестве нового вектора весов.

5. Необходимые данные для расчета градиента функции потерь:
1. Целевая функция (или функция ошибки): Это индикатор, который измеряет уровень неточности или ошибки, совершаемой моделью.
2. Вектор весов модели: Представляет собой текущие настройки или параметры модели, которые она использует для прогнозирования.
3. Наборы данных: Состоит из входных данных и их соответствующих фактических результатов, используемых для обучения и тестирования модели.
4. Настройки модели: Включают в себя количество использованных характеристик и прочие аспекты, способные повлиять на вычисление градиента, например, применение регуляризации.

6.
Учитывая предоставленные данные, вектор весов с примененной регуляризацией (w2 {0.69, 2.02, 4.20}) скорее всего демонстрирует более низкие значения коэффициентов по сравнению с вектором без регуляризации (w1 {14.37, 22.80, 32.20}). 
Это обоснованно, так как одна из ролей регуляризации - снижение абсолютных значений весов модели. Это делается для предотвращения переобучения, когда модель слишком хорошо "запоминает" обучающие данные и плохо работает с новыми, не виденными ранее, данными.

7. Оценка предсказания модели для x {1, 3, 1}:

Весы модели w: {3, -2, 2}
Параметры x: {1, 3, 1}

Предсказанное значение: w * x
                    = {3, -2, 2} * {1, 3, 1}
                    = (3*1) + (-2*3) + (2*1)
                    = 3 - 6 + 2
                    = -1

Для вычисления предсказанного значения модели, где модель представлена в виде линейной комбинации весов и параметров входных данных, мы можем использовать Python. 
Это типичная задача в машинном обучении, где модель оценивает выходное значение на основе входных признаков и набора весов.

Формула предсказания:
[ \text{Предсказанное значение} = w \cdot x ]
где ( w ) — вектор весов модели, а ( x ) — вектор входных параметров.

def predict(w, x):
    """Расчет предсказанного значения модели для данного входа x."""
    # Проверяем, что векторы одинаковой длины
    if len(w) != len(x):
        raise ValueError("Векторы весов и входных параметров должны быть одинаковой длины")
    
    # Вычисляем скалярное произведение векторов
    predicted_value = sum(weight * param for weight, param in zip(w, x))
    return predicted_value

# Весы модели
w = [3, -2, 2]
# Параметры входных данных
x = [1, 3, 1]

# Вычисление предсказанного значения
predicted_value = predict(w, x)

print("Предсказанное значение модели:", predicted_value)
Пояснение кода:
1. Функция predict используется для предсказания значения на основе заданных весов и параметров. Она принимает два аргумента: w - вектор весов, и x - вектор параметров.
2. Перед тем как сделать предсказание, функция проверяет, что оба вектора имеют одинаковую длину. Это необходимо для корректного вычисления скалярного произведения.
3. Скалярное произведение векторов w и x вычисляется путем поэлементного перемножения соответствующих элементов и суммирования результатов.
4. Полученное скалярное произведение и является предсказанным значением, которое затем выводится на экран.

8. Рассчитайте коэффициент детерминации:

Реальные значения y: {1, 2, 3, 4}
Предсказанные значения: {2, 1, 4, 6}

Сначала вычислите среднее реальных значений:
mean_y = (1 + 2 + 3 + 4) / 4 = 2.5

Затем вычислите сумму квадратов и дисперсию реальных значений:
SS_tot = (1-2.5)² + (2-2.5)² + (3-2.5)² + (4-2.5)² = 5

Вычислите сумму квадратов остатков (погрешность):
SS_res = (1-2)² + (2-1)² + (3-4)² + (4-6)² = 10

Теперь вычислите R²:
R² = 1 - (SS_res / SS_tot)
    = 1 - (10 / 5)
    = 1 - 2
    = -1

Однако R² не может быть отрицательным, что указывает на ошибку в расчете. Давайте исправим его:

SS_res = (1-2)² + (2-1)² + (3-4)² + (4-6)² = 10
SS_tot = 5 (как было рассчитано ранее)

R²
Python:

def calculate_r_squared(y_true, y_pred):
    # Среднее реальных значений
    mean_y = sum(y_true) / len(y_true)
    
    # Сумма квадратов отклонений (total sum of squares)
    ss_tot = sum((y - mean_y) ** 2 for y in y_true)
    
    # Сумма квадратов ошибок (residual sum of squares)
    ss_res = sum((y_true_i - y_pred_i) ** 2 for y_true_i, y_pred_i in zip(y_true, y_pred))
    
    # Коэффициент детерминации R^2
    r_squared = 1 - (ss_res / ss_tot)
    
    return r_squared

# Реальные значения
y_true = [1, 2, 3, 4]

# Предсказанные значения
y_pred = [2, 1, 4, 6]

# Расчёт R^2
r_squared = calculate_r_squared(y_true, y_pred)

print(f"Коэффициент детерминации R² = {r_squared}")
Пояснение кода:
1. Функция calculate_r_squared оценивает качество модели, сравнивая предсказанные значения с реальными. Она принимает два списка: y_true (реальные значения) и y_pred (предсказанные значения).
2. Сначала функция вычисляет среднее значение реальных значений (mean_y). 
   Затем она определяет, насколько сильно реальные значения отклоняются от среднего (общая сумма квадратов отклонений - ss_tot), и насколько сильно от реальных значений отличаются предсказанные значения (сумма квадратов ошибок - ss_res).
3. Наконец, функция вычисляет коэффициент детерминации (R²), который показывает, насколько хорошо модель предсказывает значения по сравнению с простой моделью, использующей только среднее значение. 
  R² принимает значения от 0 до 1, где 1 означает идеальное совпадение предсказаний с реальными значениями. 
  Отрицательное значение R² указывает на то, что модель работает хуже, чем простое предсказание средним значением, что может свидетельствовать о неправильном выборе модели или ошибках в данных.
